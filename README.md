# ğŸ¤– G1 Hierarchical VLM-ULC System

**Unified Loco-manipulation Control for Unitree G1 Humanoid Robot with Vision-Language Model Integration**

> âš ï¸ **RESEARCH IN PROGRESS â€” PAPER IN PREPARATION**  
> This repository contains original research work. If you use any part of this codebase, architecture, or methodology, **citation is required**. Unauthorized reproduction or publication of this work is prohibited. Contact the author for collaboration inquiries.

---

## ğŸ“‹ Overview

A hierarchical control system combining Vision-Language Models (VLM) with Unified Loco-manipulation Control (ULC) for long-horizon task solving on the Unitree G1 humanoid robot.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HIERARCHICAL ARCHITECTURE                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     "Go to the blue chair"                â”‚
â”‚  â”‚     VLM     â”‚ â† RGB Image + Language Command            â”‚
â”‚  â”‚ Florence-2  â”‚ â†’ Target: {x, y, object_class}            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚         â”‚ ~1 Hz (Semantic Understanding)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚  Semantic   â”‚ â†’ Object positions, scene graph           â”‚
â”‚  â”‚  World Map  â”‚ â†’ Geometric tracking (100x faster)        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚         â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚    ULC      â”‚ â† cmd_vel + arm_commands + torso_cmd      â”‚
â”‚  â”‚   Policy    â”‚ â†’ Joint Actions (22 DoF)                  â”‚
â”‚  â”‚    (PPO)    â”‚   [12 legs + 10 arms]                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚         â”‚ 50 Hz (Motor Control)                            â”‚
â”‚      [G1 ğŸ¤–]                                               â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Key Contributions

1. **Sequential Curriculum Learning:** 5-stage training from standing to full loco-manipulation
2. **Residual Action Modeling:** Stable arm control via small corrections around default poses
3. **Semantic World Model:** VLM for initial understanding + geometric tracking for real-time updates (~100x speedup)
4. **Unified Policy:** Single PPO policy for whole-body control (locomotion + torso + arms)

---

## ğŸ“Š Training Progress

| Stage | Task | Obs Dim | Act Dim | Status |
|-------|------|---------|---------|--------|
| 1 | Standing (Height Control) | 45 | 12 | âœ… Complete |
| 2 | Locomotion (Velocity Tracking) | 51 | 12 | âœ… Complete |
| 3 | Torso Control (Pitch/Roll/Yaw) | 57 | 12 | âœ… Complete |
| 4 | Arm Tracking (Residual Actions) | 77 | 22 | âœ… Complete |
| 5 | Full Integration + Workspace | 77 | 22 | ğŸ”„ In Progress |
| 6 | VLM Integration | TBD | 22 | ğŸ“‹ Planned |

---

## ğŸ› ï¸ Tech Stack

- **Simulation:** NVIDIA Isaac Lab 2.3.1, Isaac Sim 5.1.0
- **RL Framework:** RSL-RL, PyTorch, PPO
- **VLM:** Florence-2 / Molmo2
- **Robot:** Unitree G1 (29 DoF configuration)
- **Hardware:** RTX 5070 Ti (12GB VRAM), 4096 parallel environments

---

## ğŸ—ï¸ Architecture Details

### ULC Policy
- **Input:** Proprioception (joint pos/vel) + Commands (velocity, torso, arm targets) + Gait phase
- **Output:** Joint position targets for legs (12) + Residual corrections for arms (10)
- **Training:** ~17,000 steps/second with domain randomization

### Residual Action Modeling
```python
# Arms use residual actions around commanded positions
arm_targets = arm_commands + scale * tanh(policy_output)
# Legs use direct position control
leg_targets = default_pose + scale * policy_output
```

### Sequential Curriculum
Each stage builds on the previous checkpoint, progressively adding control complexity while maintaining stability.

---

## ğŸ“ Project Structure

```
isaac-g1-ulc-vlm/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ ulc_g1_env_cfg.py      # Environment configuration
â”œâ”€â”€ envs/
â”‚   â””â”€â”€ ulc_g1_env.py          # ULC environment implementation
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ train_ulc_stage_*.py   # Stage-specific training scripts
â”‚   â””â”€â”€ play_ulc_stage_*.py    # Evaluation scripts
â”œâ”€â”€ vlm/
â”‚   â”œâ”€â”€ vlm_wrapper.py         # Florence-2/Molmo2 interface
â”‚   â””â”€â”€ semantic_map.py        # World model with geometric tracking
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

```powershell
# Stage 4 Training (from Stage 3 checkpoint)
cd C:\IsaacLab
./isaaclab.bat -p source/isaaclab_tasks/.../train/train_ulc_stage_4.py \
    --stage3_checkpoint logs/ulc/stage3_best.pt \
    --num_envs 4096 --headless

# Evaluation
./isaaclab.bat -p .../play/play_ulc_stage_4.py \
    --checkpoint logs/ulc/stage4_best.pt \
    --num_envs 4
```

---

## ğŸ“š References

This work builds upon:

- [ULC: Unified Fine-Grained Controller for Humanoid Loco-Manipulation](https://arxiv.org/abs/2507.06905) - Sun et al.
- [Isaac Lab](https://isaac-sim.github.io/IsaacLab/) - NVIDIA
- [Unitree G1 Simulation](https://github.com/unitreerobotics/unitree_sim_isaaclab) - Unitree Robotics

---

## âš–ï¸ License & Citation

**This is unpublished research work.** The code is provided for reference only.

If you use this work, please cite:
```bibtex
@misc{yardimci2026g1ulcvlm,
  author = {YardÄ±mcÄ±, Mehmet Turan},
  title = {Hierarchical VLM-ULC for G1 Humanoid Loco-Manipulation},
  year = {2026},
  note = {Paper in preparation}
}
```

For collaboration or usage inquiries: mehmetturanyardimci@hotmail.com

---

## ğŸ‘¤ Author

**Mehmet Turan YardÄ±mcÄ±**  
- GitHub: [@mturan33](https://github.com/mturan33)  
- LinkedIn: [/in/mehmetturanyardimci](https://linkedin.com/in/mehmetturanyardimci)
